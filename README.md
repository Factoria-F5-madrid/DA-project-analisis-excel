# Limpieza de datos en Notebook ‚Äî Proyecto inicial (Kiva Crowdfunding)

## üìù Descripci√≥n del proyecto

Este proyecto se centrar√° en aplicar las mejores pr√°cticas de limpieza y preparaci√≥n de datos utilizando Python en un entorno de notebook (Jupyter/Google Colab). El objetivo es transformar los datos brutos del dataset de Kiva Crowdfunding en un conjunto de datos estructurado, consistente y listo para an√°lisis o modelado predictivo.

El proyecto sigue una metodolog√≠a reproducible que abarca tres etapas fundamentales: **Importaci√≥n y exploraci√≥n inicial**, **Diagn√≥stico y limpieza de datos**, y **Validaci√≥n y exportaci√≥n del dataset limpio**. Se enfatiza la documentaci√≥n clara de cada decisi√≥n tomada durante el proceso de limpieza, garantizando que cualquier miembro del equipo pueda replicar el trabajo y comprender el razonamiento detr√°s de cada transformaci√≥n aplicada.

## üéØ Objetivos concretos

- Entender la estructura y calidad raw del dataset.
- Corregir tipos, fechas y valores inconsistentes.
- Eliminar/gestionar duplicados y valores faltantes de forma documentada.
- Crear un artefacto final (CSV/Parquet) y un notebook reproducible con comentarios y celdas explicativas.

## üìä Dataset Utilizado
Para este proyecto, trabajaremos con el dataset **"Data Science for Good: Kiva Crowdfunding"** que contiene informaci√≥n sobre pr√©stamos de microfinanciaci√≥n de Kiva, una organizaci√≥n sin fines de lucro.

- **Dataset principal**: [Descargar dataset Kiva](https://drive.google.com/file/d/1hY7KOuXNyY7WPw9cICXqrxmT8iRytmJk/view?usp=sharing)
- **Informaci√≥n detallada del dataset**: [Kaggle - Kiva Crowdfunding](https://www.kaggle.com/datasets/kiva/data-science-for-good-kiva-crowdfunding)
- **Organizaci√≥n**: [Kiva.org](https://www.kiva.org/)
  
## üß∞ Tecnolog√≠as y librer√≠as

- **Python** (notebook Jupyter o Google Colab)
- **Librer√≠as:** pandas, numpy, matplotlib / seaborn (opcional para exploraci√≥n), pyarrow (si se exporta Parquet)
- **Control de versiones:** git (repositorio), README.md

### ‚ö†Ô∏è Nota sobre la elecci√≥n del dataset
**Puedes utilizar cualquier dataset de tu inter√©s** obtenido de otras fuentes de internet como Kaggle, data.gov, UCI Machine Learning Repository, o cualquier otra fuente de datos p√∫blica que sea de tu inter√©s personal o profesional.

## üì¶ Condiciones de entrega

El proyecto es **Individual**.

1. Ser√° necesario entregar un **Notebook** (.ipynb) bien organizado y con comentarios explicativos.
2. Ser√° necesario entregar el **Dataset limpio** exportado (CSV o Parquet).
3. Ser√° necesario entregar un **README** con:
   - Pasos ejecutados
   - C√≥mo ejecutar el notebook
   - Resumen de decisiones de limpieza
4. **Repositorio** con todo lo anterior.

## ‚è≥ Plazo de Entrega

- 1 semana

## üõ†Ô∏è Tecnolog√≠as a usar

- Google Colab
- Github

## üß≠ Estructura recomendada del Notebook

1. **Importar datos** (mostrar primeros registros)
2. **An√°lisis exploratorio r√°pido** (shape, tipos, resumen estad√≠stico)
3. **Diagn√≥stico de problemas** (missing, outliers, duplicados, formatos)
4. **Transformaciones y limpieza** (paso a paso, con celdas y comentarios)
5. **Validaci√≥n post-limpieza** (checks, counts, sample)
6. **Exportar dataset limpio** y notas finales

## ‚úÖ Checklist de limpieza (tareas y decisiones t√≠picas)

- [ ] Revisar columnas, tipos de datos y convertir columnas de fecha a datetime
- [ ] Detectar y eliminar duplicados (documentar criterio)
- [ ] Analizar y tratar valores faltantes: imputaci√≥n simple, eliminaci√≥n o marca expl√≠cita
- [ ] Normalizar textos (pa√≠s, moneda, categor√≠as): trim, lower, mapeos
- [ ] Corregir formatos num√©ricos (coma/punto, tipos num√©ricos)
- [ ] Detectar y gestionar outliers razonables (documentar por qu√© se quitan o conservan)**
- [ ] Crear columnas derivadas √∫tiles (ej.: a√±o, mes, duraci√≥n, ratio)
- [ ] Codificar variables categ√≥ricas si procede (labels / one-hot solo si es necesario)**
- [ ] Guardar snapshot del raw original y del dataset final**
- [ ] A√±adir pruebas sencillas: conteos esperados, no-null en campos clave, unicidad**

## üìà Buenas pr√°cticas y criterios de calidad

- **Reproducibilidad:** todo cambio debe poder ejecutarse de nuevo desde el notebook
- **Trazabilidad:** explicar por qu√© se tom√≥ cada decisi√≥n (notas/markdown)
- **Minimalismo en p√©rdida de informaci√≥n:** eliminar filas solo si hay justificaci√≥n
- **Entregable usable:** dataset final con tipos correctos y documentaci√≥n m√≠nima

## üß™ Criterios de evaluaci√≥n

- Configurar y automatizar su entorno de trabajo.
- Gestionar equipos t√©cnicos
- Evaluar Conjuntos de datos
- Desarrollar interfaces din√°micas**
